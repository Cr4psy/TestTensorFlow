{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  loss = None\n",
    "  train_op = None\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  if mode != learn.ModeKeys.INFER:\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == learn.ModeKeys.TRAIN:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=0.001,\n",
    "        optimizer=\"SGD\")\n",
    "\n",
    "  # Generate Predictions\n",
    "  predictions = {\n",
    "      \"classes\": tf.argmax(\n",
    "          input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(\n",
    "          logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  # Return a ModelFnOps object\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_environment': 'local', '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_save_checkpoints_secs': 600, '_task_id': 0, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022E6195A7F0>, '_keep_checkpoint_max': 5, '_model_dir': None, '_evaluation_master': '', '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:From <ipython-input-7-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-7-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-7-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-1571\n",
      "INFO:tensorflow:Saving checkpoints for 1572 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.25649, step = 1572\n",
      "INFO:tensorflow:probabilities = [[ 0.02739747  0.04682119  0.02975136  0.10453058  0.03015226  0.1898386\n",
      "   0.01494635  0.08904713  0.33214536  0.13536969]\n",
      " [ 0.05533403  0.09481391  0.10665422  0.07676395  0.12388349  0.18090884\n",
      "   0.08846591  0.041285    0.13288742  0.09900307]\n",
      " [ 0.15208161  0.02222831  0.02393035  0.26774213  0.01747234  0.23369411\n",
      "   0.049296    0.03341411  0.07619395  0.12394708]\n",
      " [ 0.10161442  0.00424512  0.12033771  0.06239021  0.05057905  0.0410264\n",
      "   0.51631385  0.01614858  0.04502628  0.04231833]\n",
      " [ 0.03749226  0.04183403  0.06435674  0.42993081  0.00865202  0.12258784\n",
      "   0.04858207  0.03714751  0.08673936  0.1226773 ]\n",
      " [ 0.0099507   0.04005729  0.09718078  0.54532236  0.0175202   0.03263118\n",
      "   0.01981316  0.10611857  0.05180804  0.07959774]\n",
      " [ 0.1736422   0.02748545  0.50144345  0.05462561  0.01606599  0.0434297\n",
      "   0.04689985  0.0050768   0.12334443  0.00798658]\n",
      " [ 0.0298164   0.00430491  0.17638704  0.01851194  0.03970569  0.01593041\n",
      "   0.56725627  0.01143159  0.11503688  0.02161885]\n",
      " [ 0.02682916  0.01414249  0.20501091  0.04638502  0.05092845  0.18378986\n",
      "   0.24812709  0.00683263  0.18578829  0.03216607]\n",
      " [ 0.01771252  0.10271843  0.06975567  0.28527904  0.00568949  0.03739138\n",
      "   0.01092201  0.10246892  0.28649589  0.08156662]\n",
      " [ 0.04428387  0.01291181  0.04214001  0.06737139  0.04738631  0.05489586\n",
      "   0.01104234  0.45164901  0.14692914  0.12139023]\n",
      " [ 0.06322254  0.02913571  0.18905778  0.28260991  0.02659325  0.03720354\n",
      "   0.08447722  0.14762694  0.08771028  0.05236279]\n",
      " [ 0.11701679  0.01312205  0.72659183  0.02185156  0.00570593  0.04096181\n",
      "   0.01447238  0.00769123  0.03766507  0.01492134]\n",
      " [ 0.0430542   0.0206276   0.10007931  0.06054465  0.26389375  0.03796853\n",
      "   0.03886954  0.08269171  0.07900731  0.27326337]\n",
      " [ 0.00547052  0.39183944  0.02945472  0.08177966  0.03182147  0.02725403\n",
      "   0.0557278   0.03651904  0.30659056  0.03354267]\n",
      " [ 0.05134281  0.00660647  0.11434515  0.66091621  0.00979151  0.05182348\n",
      "   0.01448029  0.02437618  0.02691826  0.03939971]\n",
      " [ 0.01370957  0.01153931  0.69437528  0.06347931  0.0207561   0.01351819\n",
      "   0.12164488  0.01570778  0.03871216  0.00655737]\n",
      " [ 0.01435631  0.1435169   0.06227889  0.27837342  0.03586745  0.17246571\n",
      "   0.04907503  0.068749    0.11726619  0.05805108]\n",
      " [ 0.05441211  0.14601456  0.09099205  0.05340509  0.01700866  0.19170749\n",
      "   0.02964926  0.02986297  0.3467814   0.04016639]\n",
      " [ 0.14124502  0.03378724  0.27554676  0.13735993  0.01016494  0.04284823\n",
      "   0.04485631  0.17540143  0.13005863  0.00873148]\n",
      " [ 0.00536686  0.60162139  0.0499416   0.08703491  0.01226084  0.03311632\n",
      "   0.04144209  0.03295911  0.06388578  0.07237105]\n",
      " [ 0.0307982   0.07245914  0.10507561  0.06702942  0.21742623  0.12513621\n",
      "   0.11398381  0.05850181  0.13849425  0.07109533]\n",
      " [ 0.00113085  0.7604748   0.00925744  0.05967068  0.00975752  0.01379494\n",
      "   0.01233006  0.06144921  0.04295097  0.02918347]\n",
      " [ 0.01562482  0.40978199  0.0367994   0.2164994   0.0032265   0.07604363\n",
      "   0.01786598  0.06753028  0.12202462  0.03460334]\n",
      " [ 0.0097995   0.02386084  0.08743107  0.04090035  0.17283987  0.06290751\n",
      "   0.46052977  0.02782307  0.05326109  0.06064694]\n",
      " [ 0.0787174   0.01044415  0.39475277  0.02315686  0.10993513  0.03943946\n",
      "   0.23486412  0.01011036  0.08452035  0.01405932]\n",
      " [ 0.01116097  0.00431305  0.00919546  0.03102438  0.43059167  0.01800628\n",
      "   0.01649652  0.09545701  0.03304194  0.35071278]\n",
      " [ 0.0896839   0.00603426  0.03711722  0.30134031  0.10207164  0.03813881\n",
      "   0.05665669  0.05945997  0.14566542  0.16383177]\n",
      " [ 0.02742749  0.0471154   0.05667226  0.18825503  0.07086374  0.119119\n",
      "   0.03673927  0.17218849  0.15133967  0.13027965]\n",
      " [ 0.0953481   0.07677715  0.03057675  0.1392363   0.02444468  0.16550162\n",
      "   0.01971674  0.15196303  0.22134754  0.07508807]\n",
      " [ 0.01068015  0.0109764   0.09061204  0.02757233  0.08420548  0.04827389\n",
      "   0.62083769  0.01128001  0.05955583  0.03600616]\n",
      " [ 0.05508329  0.01178635  0.08426438  0.07207306  0.06830547  0.10716667\n",
      "   0.47158104  0.02950193  0.05096608  0.04927179]\n",
      " [ 0.0526015   0.09337728  0.12112095  0.04445507  0.20098449  0.11938923\n",
      "   0.14092676  0.02782993  0.08149452  0.11782025]\n",
      " [ 0.01833696  0.05318999  0.0150008   0.02251645  0.19601408  0.07583579\n",
      "   0.01280921  0.42750251  0.03922939  0.1395649 ]\n",
      " [ 0.03391839  0.00235989  0.04427008  0.03107532  0.37067193  0.04378783\n",
      "   0.07416321  0.271346    0.03695167  0.09145574]\n",
      " [ 0.52888441  0.00150266  0.13828807  0.04734333  0.00490536  0.17138964\n",
      "   0.01464872  0.04058908  0.01487045  0.03757819]\n",
      " [ 0.02006351  0.0355222   0.03706992  0.0493639   0.1869514   0.16187143\n",
      "   0.03691353  0.16490795  0.04346302  0.26387322]\n",
      " [ 0.01586225  0.01710048  0.04445861  0.05728911  0.31338423  0.0594344\n",
      "   0.04582427  0.04844487  0.07942691  0.31877479]\n",
      " [ 0.35927033  0.00387099  0.04116264  0.06891168  0.04325996  0.09386232\n",
      "   0.17963219  0.05122247  0.10777006  0.05103739]\n",
      " [ 0.02366215  0.13615173  0.00935465  0.17164934  0.05986262  0.0793097\n",
      "   0.03059744  0.1304985   0.18619145  0.17272238]\n",
      " [ 0.67996418  0.00226622  0.02871967  0.04576456  0.03348247  0.04298573\n",
      "   0.01636213  0.05283369  0.02993223  0.06768904]\n",
      " [ 0.0738756   0.02413188  0.49301374  0.04335463  0.06791099  0.08320842\n",
      "   0.08428718  0.01671336  0.08728995  0.02621426]\n",
      " [ 0.01877416  0.03765301  0.05573188  0.06386737  0.079568    0.05059421\n",
      "   0.08420248  0.30321059  0.04075239  0.26564592]\n",
      " [ 0.03340983  0.01203625  0.02153682  0.06891617  0.05224462  0.02340401\n",
      "   0.03136092  0.51615351  0.0291668   0.21177113]\n",
      " [ 0.03311835  0.32942802  0.04649501  0.08420143  0.02078458  0.18431552\n",
      "   0.0217969   0.09645038  0.0958557   0.08755408]\n",
      " [ 0.00517874  0.27521834  0.04391796  0.20076868  0.02124422  0.08385016\n",
      "   0.14183259  0.0828521   0.06744582  0.07769141]\n",
      " [ 0.02005566  0.0193087   0.08677924  0.06903643  0.0251688   0.01936044\n",
      "   0.02957752  0.57749528  0.08996292  0.06325501]\n",
      " [ 0.03908498  0.06183307  0.21314158  0.42240405  0.00845766  0.07914639\n",
      "   0.02357208  0.04941019  0.08039768  0.02255234]\n",
      " [ 0.05283265  0.01314821  0.08890117  0.04732732  0.31428269  0.17944945\n",
      "   0.09319387  0.03301748  0.02824876  0.14959833]\n",
      " [ 0.06547169  0.05931191  0.04946746  0.05547993  0.05536976  0.23868534\n",
      "   0.02721713  0.07640018  0.31204268  0.06055389]\n",
      " [ 0.10983352  0.00580597  0.14805068  0.04414809  0.22331509  0.04499974\n",
      "   0.04709469  0.22626776  0.0366276   0.11385684]\n",
      " [ 0.021236    0.09365653  0.04380898  0.05910882  0.1746522   0.09324666\n",
      "   0.17756313  0.08715692  0.08270576  0.16686496]\n",
      " [ 0.01212874  0.13778663  0.22047266  0.2216056   0.00627956  0.07225049\n",
      "   0.03434726  0.04163229  0.23683237  0.01666447]\n",
      " [ 0.16856062  0.02533643  0.07527942  0.04969886  0.15839614  0.1065006\n",
      "   0.1817756   0.06699743  0.10436645  0.06308845]\n",
      " [ 0.09875488  0.08960205  0.08646794  0.04515251  0.07940321  0.11875605\n",
      "   0.12478351  0.03893995  0.25869077  0.05944905]\n",
      " [ 0.92849284  0.00006184  0.01189442  0.0043303   0.00371228  0.03096676\n",
      "   0.00928924  0.00279601  0.00660741  0.00184877]\n",
      " [ 0.10156528  0.07425936  0.13461331  0.0947275   0.06198056  0.08486886\n",
      "   0.19167824  0.0421789   0.15136741  0.06276062]\n",
      " [ 0.02632224  0.13749743  0.03247313  0.04995393  0.1185341   0.1437562\n",
      "   0.06626808  0.11241483  0.22548686  0.08729326]\n",
      " [ 0.00396314  0.75672656  0.01900977  0.06928109  0.01501062  0.01275771\n",
      "   0.02231143  0.04393122  0.02731549  0.02969286]\n",
      " [ 0.00497889  0.68518537  0.03909456  0.06825879  0.02239274  0.02461203\n",
      "   0.02820185  0.0391416   0.03966473  0.04846941]\n",
      " [ 0.00727261  0.0193026   0.04875413  0.66426468  0.02816897  0.04023921\n",
      "   0.0166346   0.05771683  0.02192577  0.0957206 ]\n",
      " [ 0.0047695   0.07247083  0.06449459  0.04521989  0.02794201  0.01790112\n",
      "   0.01609032  0.60109562  0.05526546  0.09475058]\n",
      " [ 0.78899765  0.00070346  0.07403714  0.05501301  0.00636354  0.0143454\n",
      "   0.00513024  0.0196339   0.02730864  0.00846709]\n",
      " [ 0.68386906  0.00316495  0.07180808  0.0162209   0.01699035  0.1102354\n",
      "   0.02743386  0.02235539  0.03246108  0.01546099]\n",
      " [ 0.08777278  0.01733967  0.0432536   0.35920957  0.01602077  0.07044597\n",
      "   0.02315923  0.21440993  0.06250504  0.10588343]\n",
      " [ 0.0519263   0.17551315  0.1886341   0.13620719  0.02492377  0.07473283\n",
      "   0.04314929  0.12570804  0.11637393  0.06283146]\n",
      " [ 0.0171034   0.05434828  0.16414635  0.07823298  0.04476287  0.0818739\n",
      "   0.19410236  0.14342576  0.08481126  0.13719288]\n",
      " [ 0.00771849  0.02408843  0.01841273  0.04393279  0.32985926  0.04043214\n",
      "   0.32742661  0.02709008  0.10083286  0.08020656]\n",
      " [ 0.01632728  0.0472571   0.07058814  0.04941253  0.18658586  0.09769588\n",
      "   0.22765605  0.04262501  0.09962878  0.16222341]\n",
      " [ 0.01650844  0.18816084  0.03714787  0.11047006  0.02527929  0.05362836\n",
      "   0.01613057  0.32222494  0.17839406  0.05205561]\n",
      " [ 0.0664492   0.01486986  0.041584    0.04730676  0.05027656  0.36515033\n",
      "   0.04976771  0.02154048  0.28383881  0.05921628]\n",
      " [ 0.01387179  0.27487114  0.05192801  0.24685106  0.03069674  0.11928289\n",
      "   0.08321375  0.04361881  0.0812562   0.05440959]\n",
      " [ 0.04514592  0.04657427  0.02279744  0.03197711  0.22965296  0.02089937\n",
      "   0.05749504  0.13025178  0.0961825   0.31902364]\n",
      " [ 0.01995089  0.04394979  0.13300313  0.06921991  0.1087303   0.10151756\n",
      "   0.31657925  0.05219436  0.03849001  0.11636487]\n",
      " [ 0.03332579  0.01084314  0.15201984  0.02247029  0.09996878  0.03299393\n",
      "   0.52499342  0.02940548  0.04491773  0.04906166]\n",
      " [ 0.00706058  0.3510583   0.10703336  0.08027891  0.03413328  0.0449874\n",
      "   0.07714374  0.06922872  0.13882397  0.09025168]\n",
      " [ 0.12769695  0.01237291  0.05183279  0.07261477  0.21661177  0.07557438\n",
      "   0.08317395  0.13741663  0.02088057  0.20182534]\n",
      " [ 0.01943275  0.0057061   0.07824308  0.04788526  0.01267914  0.02439862\n",
      "   0.0305282   0.59692991  0.02589831  0.1582986 ]\n",
      " [ 0.01678612  0.34183788  0.12627278  0.15322059  0.03127336  0.07260022\n",
      "   0.08187878  0.02988157  0.10120244  0.04504631]\n",
      " [ 0.10998043  0.12893441  0.12544385  0.09463985  0.03655704  0.10014231\n",
      "   0.13162515  0.03976134  0.12700337  0.10591227]\n",
      " [ 0.03928144  0.02484215  0.19878651  0.08837999  0.15817304  0.08682683\n",
      "   0.03378621  0.09425309  0.04254711  0.23312363]\n",
      " [ 0.01327707  0.00330036  0.10918736  0.65169841  0.01403274  0.02191699\n",
      "   0.0153968   0.06884479  0.05135063  0.05099491]\n",
      " [ 0.0217306   0.01768742  0.00824929  0.04068677  0.17975086  0.02768217\n",
      "   0.01761499  0.21566434  0.02271893  0.44821471]\n",
      " [ 0.1918845   0.04593167  0.10872744  0.02706817  0.06300744  0.15561087\n",
      "   0.11605334  0.07665209  0.1302951   0.08476934]\n",
      " [ 0.03185308  0.24634144  0.0727603   0.09463213  0.02077502  0.08153963\n",
      "   0.01597444  0.0345105   0.35122153  0.05039196]\n",
      " [ 0.01379962  0.01403243  0.00517988  0.0198246   0.05281958  0.04939009\n",
      "   0.00420192  0.48704389  0.07335907  0.28034902]\n",
      " [ 0.0646202   0.00442878  0.06845348  0.03004992  0.40555099  0.09020709\n",
      "   0.12115065  0.0568489   0.08123228  0.07745773]\n",
      " [ 0.70998919  0.00162308  0.07975797  0.04017961  0.01254652  0.07619862\n",
      "   0.03267438  0.00558216  0.02617675  0.01527171]\n",
      " [ 0.08838624  0.1033552   0.21272537  0.11615806  0.03290547  0.13835686\n",
      "   0.05709188  0.04450758  0.17002165  0.03649166]\n",
      " [ 0.01310409  0.2389605   0.05386988  0.09988513  0.06016698  0.1077473\n",
      "   0.0460531   0.06810649  0.20168237  0.1104241 ]\n",
      " [ 0.02292404  0.02202351  0.63414758  0.06252059  0.01974465  0.04004478\n",
      "   0.1151967   0.01209006  0.06220913  0.00909893]\n",
      " [ 0.00287674  0.34241471  0.05427678  0.26066917  0.01836355  0.02533568\n",
      "   0.03026502  0.10675721  0.05635684  0.10268436]\n",
      " [ 0.01786949  0.40614673  0.05782431  0.12493106  0.05469022  0.04387786\n",
      "   0.03861435  0.11673606  0.06627607  0.0730339 ]\n",
      " [ 0.72126758  0.00100841  0.05422809  0.03944739  0.01985026  0.07595495\n",
      "   0.00749559  0.00988862  0.06404096  0.00681816]\n",
      " [ 0.12834395  0.0104675   0.09996053  0.03427039  0.28869119  0.08331246\n",
      "   0.05460985  0.02608509  0.21970806  0.05455102]\n",
      " [ 0.00839381  0.48869675  0.06386945  0.09939808  0.03892342  0.04901491\n",
      "   0.06140797  0.05181993  0.08357453  0.05490109]\n",
      " [ 0.08925053  0.07674997  0.04451682  0.05014383  0.05124529  0.27738398\n",
      "   0.07524116  0.04876848  0.19985956  0.08684032]\n",
      " [ 0.00382124  0.67345583  0.05044053  0.08398892  0.00934656  0.02571602\n",
      "   0.04025616  0.02366327  0.03673034  0.05258133]\n",
      " [ 0.10129199  0.00331866  0.15882033  0.04816872  0.16802479  0.11221728\n",
      "   0.23566586  0.01556597  0.05146686  0.10545962]\n",
      " [ 0.00767615  0.27034435  0.03020509  0.16639099  0.04607763  0.07602347\n",
      "   0.05740106  0.13995621  0.06254489  0.14338014]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1573 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.08735.\n",
      "WARNING:tensorflow:From <ipython-input-7-6135337fe727>:36: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-7-6135337fe727>:36: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-07-14:27:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-1573\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-07-14:27:44\n",
      "INFO:tensorflow:Saving dict for global step 1573: accuracy = 0.7987, global_step = 1573, loss = 1.08916\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'accuracy': 0.79869998, 'global_step': 1573, 'loss': 1.0891577}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2855: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = learn.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  mnist_classifier.fit(\n",
    "      x=train_data,\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      steps=2,\n",
    "      monitors=[logging_hook])\n",
    "\n",
    "  # Configure the accuracy metric for evaluation\n",
    "  metrics = {\n",
    "      \"accuracy\":\n",
    "          learn.MetricSpec(\n",
    "              metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),\n",
    "  }\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_results = mnist_classifier.evaluate(\n",
    "      x=eval_data, y=eval_labels, metrics=metrics)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
