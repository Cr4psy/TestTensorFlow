{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  loss = None\n",
    "  train_op = None\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  if mode != learn.ModeKeys.INFER:\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == learn.ModeKeys.TRAIN:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=0.001,\n",
    "        optimizer=\"SGD\")\n",
    "\n",
    "  # Generate Predictions\n",
    "  predictions = {\n",
    "      \"classes\": tf.argmax(\n",
    "          input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(\n",
    "          logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  # Return a ModelFnOps object\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_environment': 'local', '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_save_checkpoints_secs': 600, '_task_id': 0, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022E607181D0>, '_keep_checkpoint_max': 5, '_model_dir': None, '_evaluation_master': '', '_tf_random_seed': None, '_is_chief': True, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:From <ipython-input-11-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-11-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-11-6135337fe727>:25: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-1575\n",
      "INFO:tensorflow:Saving checkpoints for 1576 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.18709, step = 1576\n",
      "INFO:tensorflow:probabilities = [[ 0.02095387  0.05741518  0.06703006  0.07912303  0.03122877  0.1952174\n",
      "   0.04132924  0.05350185  0.39334419  0.0608564 ]\n",
      " [ 0.04788789  0.09370802  0.16522221  0.05307674  0.11777321  0.18195209\n",
      "   0.08294783  0.04748334  0.13660234  0.07334626]\n",
      " [ 0.06955378  0.0283976   0.04761805  0.190953    0.01200705  0.34117231\n",
      "   0.0307759   0.11804919  0.12048     0.04099308]\n",
      " [ 0.15228002  0.0068001   0.14067423  0.03775275  0.19413081  0.07121329\n",
      "   0.28303242  0.03159907  0.031829    0.05068824]\n",
      " [ 0.019774    0.05264567  0.03386787  0.41552094  0.05932781  0.10732214\n",
      "   0.04043525  0.06840526  0.1299856   0.07271542]\n",
      " [ 0.00866046  0.01474906  0.05646133  0.67929971  0.00747303  0.08427483\n",
      "   0.03154051  0.02633818  0.05368443  0.03751841]\n",
      " [ 0.15214805  0.03350962  0.2202646   0.28406492  0.01031314  0.07666066\n",
      "   0.04308534  0.02295589  0.14373212  0.01326561]\n",
      " [ 0.07337787  0.00507961  0.14450032  0.05928433  0.10850008  0.03949051\n",
      "   0.38408235  0.01390046  0.11246105  0.05932353]\n",
      " [ 0.04733232  0.01952434  0.08798542  0.04501209  0.06145354  0.09639535\n",
      "   0.54423255  0.01502352  0.03943095  0.04360993]\n",
      " [ 0.0103832   0.04557544  0.07604711  0.36337274  0.00332642  0.07805958\n",
      "   0.00534074  0.26022771  0.06637409  0.09129301]\n",
      " [ 0.01225614  0.0178169   0.01402383  0.03382272  0.08883011  0.03926871\n",
      "   0.01622723  0.64522469  0.06659006  0.06593961]\n",
      " [ 0.03508012  0.03222208  0.41074947  0.22956041  0.01145903  0.0264741\n",
      "   0.07631271  0.08055167  0.07903551  0.01855494]\n",
      " [ 0.10566651  0.01281699  0.52171284  0.08435662  0.00677758  0.04051254\n",
      "   0.09804159  0.01885425  0.0975363   0.0137248 ]\n",
      " [ 0.07036488  0.01934892  0.06418624  0.09643225  0.22298749  0.09309042\n",
      "   0.05078799  0.06861351  0.05317548  0.26101282]\n",
      " [ 0.01645224  0.24018642  0.04776953  0.10703357  0.05751081  0.12568031\n",
      "   0.13570319  0.03421365  0.17785308  0.05759719]\n",
      " [ 0.01136087  0.01721251  0.11109662  0.69867396  0.00160984  0.02634746\n",
      "   0.00305829  0.06488809  0.05044768  0.01530456]\n",
      " [ 0.00566343  0.01500929  0.68372232  0.10689347  0.01090662  0.0233045\n",
      "   0.07778275  0.00797218  0.05341881  0.01532656]\n",
      " [ 0.01334499  0.13702674  0.10015049  0.15496176  0.03433714  0.12311084\n",
      "   0.10002725  0.07471801  0.18525605  0.07706664]\n",
      " [ 0.06017875  0.06993338  0.13054448  0.07085629  0.02175239  0.12125067\n",
      "   0.03655491  0.05123646  0.41581938  0.02187338]\n",
      " [ 0.10295657  0.08231277  0.23901276  0.17891857  0.03078851  0.08813426\n",
      "   0.05174872  0.08909804  0.10267196  0.03435781]\n",
      " [ 0.00438963  0.68839079  0.01982841  0.0537037   0.02333467  0.01866886\n",
      "   0.04123305  0.06175154  0.05127914  0.0374202 ]\n",
      " [ 0.05078331  0.05648726  0.15440577  0.0438443   0.10782412  0.21792938\n",
      "   0.19347933  0.03553693  0.08914147  0.05056808]\n",
      " [ 0.00179944  0.72865474  0.02098612  0.04004462  0.01415015  0.02566388\n",
      "   0.0138653   0.04446762  0.07306731  0.03730079]\n",
      " [ 0.03619789  0.32502308  0.06671864  0.16040605  0.01430339  0.159216\n",
      "   0.01697338  0.06684579  0.11180101  0.04251476]\n",
      " [ 0.01196235  0.05353358  0.13829817  0.0506878   0.06855471  0.04355548\n",
      "   0.5130232   0.02108688  0.05815001  0.04114779]\n",
      " [ 0.11196039  0.0480295   0.13557118  0.03463456  0.16279596  0.07811362\n",
      "   0.34197545  0.01268044  0.05213661  0.02210219]\n",
      " [ 0.01890034  0.02641623  0.03347145  0.03233944  0.28295049  0.04439685\n",
      "   0.02789104  0.13520139  0.13693391  0.26149881]\n",
      " [ 0.11599137  0.01021089  0.04616849  0.3964628   0.03356526  0.10524467\n",
      "   0.04079853  0.09342485  0.0794251   0.07870806]\n",
      " [ 0.03724989  0.01742666  0.0529127   0.15282324  0.06521997  0.22213906\n",
      "   0.05151456  0.10089742  0.21723939  0.08257712]\n",
      " [ 0.05752255  0.05793188  0.01537951  0.15238732  0.02468394  0.29522336\n",
      "   0.02557537  0.03033688  0.29611138  0.04484789]\n",
      " [ 0.01785649  0.02177657  0.14514156  0.03667865  0.07059355  0.06691705\n",
      "   0.57325947  0.01866261  0.03339533  0.01571874]\n",
      " [ 0.09010068  0.01325834  0.07494433  0.11590023  0.04149756  0.07157097\n",
      "   0.47764882  0.02098716  0.06361997  0.03047203]\n",
      " [ 0.0491755   0.05309221  0.03939899  0.08014037  0.16397557  0.19153464\n",
      "   0.19352564  0.03400037  0.0829497   0.11220713]\n",
      " [ 0.00653786  0.04677769  0.00689211  0.02713471  0.08780228  0.03208955\n",
      "   0.0101619   0.47942376  0.04421396  0.25896615]\n",
      " [ 0.08060833  0.01250951  0.06093262  0.02755252  0.37422821  0.10917668\n",
      "   0.0472251   0.14364862  0.02929486  0.11482356]\n",
      " [ 0.81091326  0.00049848  0.07085262  0.00915177  0.00467094  0.01405467\n",
      "   0.00462322  0.0096114   0.07344061  0.00218284]\n",
      " [ 0.04179116  0.03240974  0.05765406  0.08549853  0.12392882  0.09207007\n",
      "   0.03696888  0.14563121  0.07856945  0.3054781 ]\n",
      " [ 0.01118068  0.00685227  0.01746846  0.0376123   0.25110257  0.07946944\n",
      "   0.035135    0.11560223  0.0232228   0.42235422]\n",
      " [ 0.41325569  0.00420772  0.06432662  0.06133414  0.0207314   0.13215324\n",
      "   0.15776664  0.03552382  0.06468174  0.04601903]\n",
      " [ 0.00721545  0.27686039  0.01623802  0.08337505  0.04142568  0.03710045\n",
      "   0.08862896  0.22393151  0.10031273  0.12491184]\n",
      " [ 0.70909411  0.00211253  0.02426082  0.03880466  0.01760102  0.07974601\n",
      "   0.01545617  0.04757171  0.02712423  0.0382288 ]\n",
      " [ 0.05511456  0.0223251   0.55647206  0.04008516  0.03895227  0.10512553\n",
      "   0.09696554  0.01464114  0.04382681  0.02649171]\n",
      " [ 0.01790017  0.04734677  0.03585912  0.04579253  0.17777906  0.07567563\n",
      "   0.02815591  0.20023347  0.07178327  0.29947409]\n",
      " [ 0.04340542  0.01362447  0.02143158  0.04742606  0.09933209  0.03215865\n",
      "   0.0233647   0.47362441  0.03434232  0.21129028]\n",
      " [ 0.03994139  0.22276597  0.04066768  0.17247438  0.0127912   0.25756222\n",
      "   0.02163397  0.07265019  0.11533784  0.04417517]\n",
      " [ 0.00849009  0.30770722  0.03758277  0.11703424  0.03813075  0.07097954\n",
      "   0.18634599  0.08301781  0.05109345  0.09961813]\n",
      " [ 0.09569889  0.00957411  0.08746109  0.08869372  0.07442039  0.0957531\n",
      "   0.05336912  0.24826954  0.15482894  0.09193108]\n",
      " [ 0.04618355  0.02834685  0.33546793  0.38568875  0.00951737  0.03897497\n",
      "   0.01493179  0.03619899  0.09734295  0.00734681]\n",
      " [ 0.01823078  0.02091997  0.04665751  0.04567529  0.34113494  0.06206309\n",
      "   0.22237095  0.02142234  0.08564119  0.1358839 ]\n",
      " [ 0.17362128  0.03778446  0.02471078  0.05081194  0.03159703  0.42399192\n",
      "   0.02540318  0.05458814  0.14882049  0.02867076]\n",
      " [ 0.06156868  0.00753464  0.15676716  0.02666801  0.34649318  0.07609293\n",
      "   0.04307292  0.08926021  0.02654165  0.16600055]\n",
      " [ 0.01772367  0.11600202  0.1030058   0.0659702   0.1857647   0.12558536\n",
      "   0.0835114   0.10087045  0.07524672  0.12631972]\n",
      " [ 0.0125185   0.29380408  0.18081222  0.17422862  0.01031857  0.12336173\n",
      "   0.0232796   0.05764204  0.10031887  0.02371585]\n",
      " [ 0.1956967   0.02866797  0.16329931  0.0657871   0.13096184  0.12336629\n",
      "   0.11802084  0.04736825  0.07402612  0.05280552]\n",
      " [ 0.06978343  0.12948024  0.09389124  0.08143137  0.04229181  0.1556056\n",
      "   0.10592527  0.05120259  0.21533662  0.05505184]\n",
      " [ 0.9603436   0.00049674  0.00406599  0.00909856  0.00091216  0.00526133\n",
      "   0.00221904  0.00217614  0.01361827  0.00180809]\n",
      " [ 0.05530862  0.04385904  0.14286904  0.08784852  0.06484679  0.12452407\n",
      "   0.22029324  0.05426748  0.12055569  0.08562748]\n",
      " [ 0.03569443  0.11644519  0.02409542  0.07279807  0.05902863  0.11428427\n",
      "   0.06995734  0.16728091  0.16973488  0.17068078]\n",
      " [ 0.00425694  0.59938198  0.03968583  0.08807314  0.0310035   0.02672424\n",
      "   0.04002279  0.03661053  0.05351129  0.08072984]\n",
      " [ 0.00865268  0.53987342  0.02423749  0.09515139  0.03465261  0.04661923\n",
      "   0.03817376  0.10289569  0.0445792   0.06516448]\n",
      " [ 0.01281525  0.03250551  0.04106363  0.5106324   0.02701941  0.06318471\n",
      "   0.01250999  0.12107365  0.06556466  0.11363077]\n",
      " [ 0.02054714  0.07315326  0.16027877  0.0764922   0.01847199  0.01824117\n",
      "   0.01018734  0.37631431  0.17370859  0.07260519]\n",
      " [ 0.6060493   0.00052621  0.06093452  0.14855368  0.00304797  0.03145992\n",
      "   0.03710709  0.05791984  0.04734886  0.00705265]\n",
      " [ 0.67662847  0.00193386  0.0983927   0.01505814  0.03607837  0.07200243\n",
      "   0.04852251  0.01122368  0.02680519  0.01335462]\n",
      " [ 0.0254978   0.00676581  0.0246148   0.42886135  0.00490543  0.12287415\n",
      "   0.0144155   0.20727959  0.05628557  0.10850001]\n",
      " [ 0.07020824  0.21498603  0.21979389  0.08858047  0.01034778  0.05939845\n",
      "   0.03817064  0.06530538  0.17776746  0.05544167]\n",
      " [ 0.04443932  0.07283466  0.16670215  0.11119066  0.10344588  0.06811018\n",
      "   0.11213188  0.13030846  0.09321924  0.09761757]\n",
      " [ 0.01747836  0.08686707  0.06546738  0.05861967  0.14017859  0.04546795\n",
      "   0.22383533  0.05013612  0.13635203  0.17559747]\n",
      " [ 0.01131929  0.0413905   0.05876835  0.06056578  0.15478377  0.09014651\n",
      "   0.18825468  0.05319481  0.08544143  0.25613487]\n",
      " [ 0.00562661  0.12968525  0.04590657  0.1111688   0.010244    0.02014931\n",
      "   0.01066133  0.46148679  0.12701245  0.07805889]\n",
      " [ 0.07330727  0.01248967  0.03295521  0.11274201  0.01225839  0.49271187\n",
      "   0.05972783  0.01307604  0.17105122  0.01968052]\n",
      " [ 0.01463051  0.33629176  0.04332349  0.09906586  0.08618554  0.07721027\n",
      "   0.05499081  0.06742459  0.12199441  0.09888273]\n",
      " [ 0.02680319  0.06372496  0.06319544  0.0413378   0.19494076  0.05074883\n",
      "   0.04422999  0.09378931  0.10162199  0.31960768]\n",
      " [ 0.04886414  0.04093511  0.24112958  0.05164245  0.07167467  0.05925911\n",
      "   0.3188059   0.02910036  0.06502672  0.07356197]\n",
      " [ 0.02912279  0.0025677   0.15484639  0.05938989  0.23723684  0.08272742\n",
      "   0.2674596   0.03319669  0.04025777  0.0931949 ]\n",
      " [ 0.00726588  0.23831162  0.04944256  0.05574601  0.06709179  0.05763385\n",
      "   0.04628046  0.07687131  0.29031399  0.11104243]\n",
      " [ 0.04862396  0.0041474   0.07579164  0.04732692  0.27606151  0.08195222\n",
      "   0.07728562  0.1846689   0.01931204  0.18482982]\n",
      " [ 0.06911837  0.00775692  0.02478224  0.03338062  0.03569071  0.03379211\n",
      "   0.02351363  0.66096848  0.09016705  0.02082988]\n",
      " [ 0.0101888   0.42401871  0.08024952  0.10194114  0.0189984   0.07324849\n",
      "   0.08833245  0.04542194  0.11599141  0.04160915]\n",
      " [ 0.0490835   0.03725953  0.11801614  0.13534318  0.03287353  0.13463016\n",
      "   0.10486168  0.07568017  0.23974644  0.07250563]\n",
      " [ 0.0239937   0.00747685  0.05979352  0.04235927  0.47970593  0.02796956\n",
      "   0.04850839  0.04589198  0.04135622  0.22294465]\n",
      " [ 0.02580808  0.00456516  0.05685399  0.62576997  0.02149685  0.0595604\n",
      "   0.03393151  0.05329604  0.07113679  0.04758114]\n",
      " [ 0.02920719  0.00900376  0.01388123  0.02235979  0.15668072  0.08677726\n",
      "   0.01625495  0.15712062  0.02084327  0.48787123]\n",
      " [ 0.20126639  0.04998658  0.09048293  0.10776132  0.03346907  0.11905366\n",
      "   0.1520144   0.02349507  0.12591428  0.09655628]\n",
      " [ 0.05523082  0.06303608  0.02700173  0.16873299  0.01540079  0.04103666\n",
      "   0.11120626  0.02372442  0.4558976   0.03873264]\n",
      " [ 0.01106693  0.03401282  0.02589999  0.04646609  0.06694901  0.04811522\n",
      "   0.0100087   0.59206003  0.03514962  0.13027152]\n",
      " [ 0.03675151  0.00345916  0.05607051  0.01654709  0.55602193  0.02040927\n",
      "   0.06808423  0.06597001  0.05363032  0.12305608]\n",
      " [ 0.71473062  0.00182148  0.04735431  0.05825245  0.0092767   0.05483982\n",
      "   0.03383823  0.02003104  0.0473613   0.01249406]\n",
      " [ 0.0507487   0.09611088  0.15876639  0.05594269  0.03477104  0.25783885\n",
      "   0.16707818  0.03390698  0.08848838  0.05634784]\n",
      " [ 0.0156804   0.24627358  0.08892015  0.13445301  0.0343825   0.07854791\n",
      "   0.06144731  0.05894469  0.14137214  0.13997833]\n",
      " [ 0.02607439  0.05269729  0.62638891  0.0484217   0.01629837  0.06753977\n",
      "   0.0465463   0.01778052  0.08554474  0.01270804]\n",
      " [ 0.00410343  0.41126248  0.03747486  0.11429022  0.01966953  0.07691374\n",
      "   0.03681674  0.1586358   0.02288073  0.11795241]\n",
      " [ 0.01726218  0.4117358   0.062089    0.14588757  0.04849016  0.06980059\n",
      "   0.03606733  0.07623974  0.06628409  0.06614351]\n",
      " [ 0.69474936  0.00121522  0.1061018   0.03636929  0.00497555  0.06343274\n",
      "   0.01858043  0.01977929  0.02474848  0.03004789]\n",
      " [ 0.04789413  0.01535381  0.04446658  0.03170269  0.11348959  0.1197243\n",
      "   0.04240316  0.08455113  0.38070631  0.1197083 ]\n",
      " [ 0.01036186  0.40109831  0.03452403  0.14451474  0.04121602  0.06721326\n",
      "   0.06592808  0.05019372  0.09602607  0.08892383]\n",
      " [ 0.06523671  0.08607997  0.14454907  0.05458159  0.11124763  0.17419484\n",
      "   0.0721228   0.07683052  0.16267547  0.05248135]\n",
      " [ 0.00399956  0.61883759  0.02710792  0.07160572  0.01165334  0.04174187\n",
      "   0.04053633  0.02719652  0.13583049  0.02149074]\n",
      " [ 0.22906771  0.00112146  0.10560378  0.10052098  0.1171235   0.15787344\n",
      "   0.07135943  0.02344325  0.06228894  0.13159756]\n",
      " [ 0.01321111  0.33904669  0.0356788   0.15255408  0.03917176  0.06545532\n",
      "   0.04471119  0.12031092  0.10309825  0.08676183]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1577 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.13289.\n",
      "WARNING:tensorflow:From <ipython-input-11-6135337fe727>:36: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-11-6135337fe727>:36: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-07-14:44:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-1577\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-07-14:45:03\n",
      "INFO:tensorflow:Saving dict for global step 1577: accuracy = 0.7998, global_step = 1577, loss = 1.08349\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'accuracy': 0.79979998, 'global_step': 1577, 'loss': 1.0834868}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2855: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = learn.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  mnist_classifier.fit(\n",
    "      x=train_data,\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      steps=2,\n",
    "      monitors=[logging_hook])\n",
    "\n",
    "  # Configure the accuracy metric for evaluation\n",
    "  metrics = {\n",
    "      \"accuracy\":\n",
    "          learn.MetricSpec(\n",
    "              metric_fn=tf.metrics.accuracy, prediction_key=\"classes\"),\n",
    "  }\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_results = mnist_classifier.evaluate(\n",
    "      x=eval_data, y=eval_labels, metrics=metrics)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
